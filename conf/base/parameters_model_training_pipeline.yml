model_training_pipeline.feature_splitting:
  target:  total_consumption 
  threshold:  2010-05-17 

# Parameters specific to the XGBoost model
model_training_pipeline.xgboost_model_params:
  base_score: 0.5
  booster: 'gbtree'
  n_estimators: 1000
  early_stopping_rounds: 50
  objective: 'reg:squarederror'
  max_depth: 3
  learning_rate: 0.01
  verbose_eval: 100
  data_types:
    boolean_columns: ['is_holiday','conditions_clear', 'conditions_overcast', 'conditions_partiallycloudy', 
      'conditions_rain', 'conditions_rainovercast', 'conditions_rainpartiallycloudy', 
      'conditions_snowovercast', 'conditions_snowpartiallycloudy', 
      'conditions_snowrain', 'conditions_snowrainovercast', 'conditions_snowrainpartiallycloudy'
    ]

# Parameters specific to the Random Forest model
model_training_pipeline.random_forest_model_params:
  n_estimators: 600
  max_depth: 3
  random_state: 42